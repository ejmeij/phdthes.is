<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Summary and Conclusions</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- mathml,index=2,3,html --> 
<meta name="src" content="thesis-emeij.tex"> 
<meta name="date" content="2010-11-28 20:26:00"> 
<link rel="stylesheet" type="text/css" href="thesis-emeij.css"> 
</head><body 
>
   <table cellspacing="5"><tr><td class="clinks"><a 
href="thesis-emeijch7.html#thesis-emeijse38.html" >Up</a></td><td class="clinks"><a 
href="thesis-emeijse37.html" >Prev</a></td><td class="clinks"><a 
href="thesis-emeijse37.html#tailthesis-emeijse37.html" >PrevTail</a></td><td class="clinks"><a 
href="#tailthesis-emeijse38.html">Tail</a></td></tr></table><h3 class="sectionHead"><span class="titlemark">7.4    </span> <a 
 id="x52-1250004"></a>Summary and Conclusions</h3>
<!--l. 440--><p class="noindent" >In this chapter we have presented a query modeling method that brings together
intuitions from the preceding chapters. It proceeds by using the conceptual mapping
approach from Chapter&#x00A0;<a 
href="thesis-emeijch6.html#x39-860006">6<!--tex4ht:ref: chap:linkingconcepts --></a>&#x00A0;to map open domain queries to DBpedia. Next, we use the
natural language associated with each concept (in the form of the text of the
accompanying Wikipedia article) to estimate a query model. This approach serves as a
means to (i) understanding a query, by identifying concepts meant by it and (ii)
leveraging the natural language associated with those concepts to improve end-to-end
retrieval performance.
<!--l. 445--><p class="indent" >   The research questions we have addressed in this chapter are as follows.
     <dl class="description"><dt class="description">
<span 
class="bchb8t-">RQ 4.</span> </dt><dd 
class="description">What are the effects on retrieval performance of applying pseudo relevance
     feedback methods to texts associated with concepts that are automatically
     mapped from ad hoc queries?</dd></dl>
<!--l. 451--><p class="noindent" >On a relatively small web collection, we have found small but significant improvements
over a query likelihood baseline. On a much larger web corpus, we have achieved
improvements on all metrics, whether precision or recall oriented, especially when
relying exclusively on externally derived contributions to the query model. In some
cases, the concept selection stage does not classify any concepts as being relevant to
the query, which results in obtaining the same performance as the baseline.
Averaged over all topics, however, the estimated query models using the found
concepts result in significantly improved retrieval performance in terms of
precision.
     <dl class="description"><dt class="description">
<span 
class="bchb8t-">RQ 4a.</span>  </dt><dd 
class="description">What are the differences with respect to pseudo relevance estimations
     on the collection? And when the query models are estimated using pseudo
     relevance estimations on the concepts&#x2019; texts?</dd></dl>
<!--l. 459--><p class="noindent" >On the TREC Terabyte collection, we have found improvements of our model over RM-1
estimated on pseudo relevant documents from the collection in terms of both
recall and early precision. When estimated on the concepts&#x2019; texts, we have
observed that RM-1 yields the highest <a 
href="thesis-emeijli3.html#MRR">MRR</a> (although only slightly better than
WP-SVM).
<!--l. 464--><p class="indent" >   On the TREC Web 2009 test collection, we have found that our approach improves
over pseudo relevance feedback on all measures. Applying pseudo relevance feedback
for query modeling does not seem to help on this test collection, neither when
estimated on documents from the collection, nor when estimated on Wikipedia. In the
                                                                   
                                                                   
latter case, early precision is slightly (and significantly) improved over the baseline,
whereas eMAP is significantly worse.
     <dl class="description"><dt class="description">
<span 
class="bchb8t-">RQ 4b.</span>  </dt><dd 
class="description">Is the approach mainly a recall- or precision-enhancing device? Or does
     it help other aspects, such as promoting diversity?</dd></dl>
<!--l. 470--><p class="noindent" >On the TREC Terabyte test collection, we have found significant increases in terms of both
recall and early precision; a finding corroborated on the TREC Web test collection.
There, we have observed substantial gains in terms of both traditional metrics and
diversity measures. When considering diversity, we have observed major improvements
using our approach.
<!--l. 472--><p class="indent" >   In sum, we have shown that employing the texts associated with automatically
identified concepts for query modeling can improve end-to-end retrieval performance.
This effect is most notable on a recent, realistically sized document collection of
crawled web pages. Using diversity measures put forward on that test collection, we
have also noted that WP-SVM is able to substantially improve the diversity of the result
list.
                                                                   
                                                                   
<!--l. 24--><p class="indent" >   <table cellspacing="5"><tr><td class="clinks"><a 
href="thesis-emeijch7.html#thesis-emeijse38.html" >Up</a></td><td class="clinks"><a 
href="thesis-emeijse37.html" >Prev</a></td><td class="clinks"><a 
href="thesis-emeijse37.html#tailthesis-emeijse37.html" >PrevTail</a></td><td class="clinks"><a 
href="thesis-emeijse38.html" >Front</a></td></tr></table><a 
 id="tailthesis-emeijse38.html"></a> 
</body></html> 
